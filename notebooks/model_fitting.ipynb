{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import *\n",
    "from utils.data import *\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_values_df = get_hf_max_values(\"../data/hf-max_values.pkl.gzip\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example of online learning on SoyKB dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = \"soykb\"\n",
    "\n",
    "with open(f\"dataset/{dataset}-split_75_0_25.static\", \"rb\") as f:\n",
    "    [train, _, test] = pickle.load(f)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step = 10\n",
    "n_past = 5 * 60\n",
    "n_future = 5 * 60\n",
    "\n",
    "features = (0, 1, 2, 3, 6, 9, 11)\n",
    "n_features = len(features)\n",
    "n_static = 8\n",
    "features_pred = (1, 2)\n",
    "n_features_pred = len(features_pred)\n",
    "split_stride = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(f\"dataset/{dataset}-split_75_0_25-step_{step}s-past_{n_past}s-future_{n_future}s.dynamic\", \"rb\") as f:\n",
    "    [train_series, _, test_series] = pickle.load(f)\n",
    "\n",
    "series_scaler = MaxAbsScaler()\n",
    "series_scaler.fit([max_values_df.loc[train.index].max()])\n",
    "train_series_scaled = [series_scaler.transform(serie) for serie in train_series]\n",
    "test_series_scaled = [series_scaler.transform(serie) for serie in test_series]\n",
    "\n",
    "X_train, y_train = dataset_split_many_2_many(train_scaled, train_series_scaled, n_past//step, n_future//step, features, features_pred)\n",
    "X_test, y_test = dataset_split_many_2_many(test_scaled, test_series_scaled, n_past//step, n_future//step, features, features_pred)\n",
    "\n",
    "model = example_encoder_decoder_model(\n",
    "  n_features = n_features,\n",
    "  n_features_pred = n_features_pred,\n",
    "  n_static = n_static,\n",
    "  n_past = (n_past//step),\n",
    "  n_future = (n_future//step),\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "\n",
    "train_indexes = np.random.permutation(range(len(train)))\n",
    "\n",
    "for train_index in train_indexes:\n",
    "    X = X_train[train_index]\n",
    "    y = y_train[train_index]\n",
    "    samples = y.shape[0]\n",
    "    model.fit(\n",
    "      X,\n",
    "      y,\n",
    "      epochs=1,\n",
    "      batch_size=1,\n",
    "      verbose=1,\n",
    "      callbacks=[]\n",
    "    )\n",
    "\n",
    "    # restart states after fitting each of the sequences\n",
    "    model.reset_states()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}